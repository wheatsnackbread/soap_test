{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python Platform: macOS-13.3.1-arm64-arm-64bit\n",
      "Tensor Flow Version: 2.12.0\n",
      "Keras Version: 2.12.0\n",
      "\n",
      "Python 3.9.6 (default, Mar 10 2023, 20:16:38) \n",
      "[Clang 14.0.3 (clang-1403.0.22.14.1)]\n",
      "Pandas 1.5.3\n",
      "Scikit-Learn 1.2.1\n",
      "SciPy 1.10.0\n",
      "GPU is available\n"
     ]
    }
   ],
   "source": [
    "# Testing GPU compatibility\n",
    "\n",
    "import sys\n",
    "import tensorflow.keras\n",
    "import pandas as pd\n",
    "import sklearn as sk\n",
    "import scipy as sp\n",
    "import tensorflow as tf\n",
    "import platform\n",
    "print(f\"Python Platform: {platform.platform()}\")\n",
    "print(f\"Tensor Flow Version: {tf.__version__}\")\n",
    "print(f\"Keras Version: {tensorflow.keras.__version__}\")\n",
    "print()\n",
    "print(f\"Python {sys.version}\")\n",
    "print(f\"Pandas {pd.__version__}\")\n",
    "print(f\"Scikit-Learn {sk.__version__}\")\n",
    "print(f\"SciPy {sp.__version__}\")\n",
    "gpu = len(tf.config.list_physical_devices('GPU'))>0\n",
    "print(\"GPU is\", \"available\" if gpu else \"NOT AVAILABLE\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "38d41313",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading (…)\"tf_model.h5\";: 100%|██████████| 268M/268M [00:13<00:00, 19.7MB/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metal device set to: Apple M1 Pro\n",
      "\n",
      "systemMemory: 16.00 GB\n",
      "maxCacheSize: 5.33 GB\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All model checkpoint layers were used when initializing TFDistilBertForSequenceClassification.\n",
      "\n",
      "All the layers of TFDistilBertForSequenceClassification were initialized from the model checkpoint at distilbert-base-uncased-finetuned-sst-2-english.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFDistilBertForSequenceClassification for predictions without further training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'label': 'NEGATIVE', 'score': 0.9987429976463318}\n",
      "{'label': 'NEGATIVE', 'score': 0.9994571805000305}\n",
      "{'label': 'POSITIVE', 'score': 0.9998809099197388}\n",
      "Tokens: ['however', ',', 'this', 'means', 'the', 'main', 'version', 'may', 'not', 'always', 'be', 'stable', '.', 'we', 'strive', 'to', 'keep', 'the', 'main', 'version', 'operational', ',', 'and', 'most', 'issues', 'are', 'usually', 'resolved', 'within', 'a', 'few', 'hours', 'or', 'a', 'day', '.', 'if', 'you', 'run', 'into', 'a', 'problem', ',', 'please', 'open', 'an', 'issue', 'so', 'we', 'can', 'fix', 'it', 'even', 'sooner', '!']\n",
      "Token IDs: [2174, 1010, 2023, 2965, 1996, 2364, 2544, 2089, 2025, 2467, 2022, 6540, 1012, 2057, 29453, 2000, 2562, 1996, 2364, 2544, 6515, 1010, 1998, 2087, 3314, 2024, 2788, 10395, 2306, 1037, 2261, 2847, 2030, 1037, 2154, 1012, 2065, 2017, 2448, 2046, 1037, 3291, 1010, 3531, 2330, 2019, 3277, 2061, 2057, 2064, 8081, 2009, 2130, 10076, 999]\n",
      "Input IDs: {'input_ids': [101, 2174, 1010, 2023, 2965, 1996, 2364, 2544, 2089, 2025, 2467, 2022, 6540, 1012, 2057, 29453, 2000, 2562, 1996, 2364, 2544, 6515, 1010, 1998, 2087, 3314, 2024, 2788, 10395, 2306, 1037, 2261, 2847, 2030, 1037, 2154, 1012, 2065, 2017, 2448, 2046, 1037, 3291, 1010, 3531, 2330, 2019, 3277, 2061, 2057, 2064, 8081, 2009, 2130, 10076, 999, 102], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "from transformers import AutoTokenizer, TFAutoModelForSequenceClassification\n",
    "import torch.nn.functional as F\n",
    "\n",
    "model_name = \"distilbert-base-uncased-finetuned-sst-2-english\"\n",
    "\n",
    "model = TFAutoModelForSequenceClassification.from_pretrained(model_name)\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "\n",
    "classifier = pipeline(\"sentiment-analysis\", model=model, tokenizer=tokenizer)\n",
    "\n",
    "results = classifier([\"However, this means the main version may not always be stable. We strive to keep the main version operational, and most issues are usually resolved within a few hours or a day. If you run into a problem, please open an Issue so we can fix it even sooner!\", \"I'm so sad\", \"I'm so happy\"])\n",
    "\n",
    "for result in results:\n",
    "    print(result)\n",
    "\n",
    "tokens = tokenizer.tokenize(\"However, this means the main version may not always be stable. We strive to keep the main version operational, and most issues are usually resolved within a few hours or a day. If you run into a problem, please open an Issue so we can fix it even sooner!\")\n",
    "token_ids = tokenizer.convert_tokens_to_ids(tokens)\n",
    "input_ids = tokenizer(\"However, this means the main version may not always be stable. We strive to keep the main version operational, and most issues are usually resolved within a few hours or a day. If you run into a problem, please open an Issue so we can fix it even sooner!\")\n",
    "\n",
    "\n",
    "print(f'Tokens: {tokens}')\n",
    "print(f'Token IDs: {token_ids}')\n",
    "print(f'Input IDs: {input_ids}')\n",
    "\n",
    "X_train = [\"However, this means the main version may not always be stable. We strive to keep the main version operational, and most issues are usually resolved within a few hours or a day.\",  \"If you run into a problem, please open an Issue so we can fix it even sooner!\"]\n",
    "\n",
    "batch = tokenizer(X_train, padding=True, truncation=True, max_length=512, return_tensors=\"pt\") "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
